Model: gemini-2.0-flash-exp
Tool: get_docs
Args: {
  "library": "langchain",
  "query": "Chroma DB integration"
}
Raw Result: meta=None content=[TextContent(type='text', text='Documentation search results for \'Chroma DB integration\' in langchain:\n\n=== Result 1: Chroma ===\nURL: https://python.langchain.com/docs/integrations/vectorstores/chroma/\n\nChroma | ??? LangChain Skip to main contentOur Building Ambient Agents with LangGraph course is now available on LangChain Academy!On this page This notebook covers how to get started with the Chroma vector store. Chroma is a AI-native open-source vector database focused on developer productivity and happiness. Chroma is licensed under Apache 2.0. View the full docs of Chroma at this page, and find the API reference for the LangChain integration at this page. Chroma CloudChroma Cloud powers serverless vector and full-text search. It\'s extremely fast, cost-effective, scalable and painless. Create a DB and try it out in under 30 seconds with $5 of free credits.Get started with Chroma Cloud Setup? To access Chroma vector stores you\'ll need to install the langchain-chroma integration package. pip install -qU "langchain-chroma>=0.1.2" Credentials? You can use the Chroma vector store without any credentials, simply installing the package above is enough! If you are a Chroma Cloud user, set your CHROMA_TENANT, CHROMA_DATABASE, and CHROMA_API_KEY environment variables. When you install the chromadb package you also get access to the Chroma CLI, which can set these for you. First, login via the CLI, and then use the connect command: chroma db connect [db_name] --env-file If you want to get best in-class automated tracing of your model calls you can also set your LangSmith API key by uncommenting below: # os.environ["LANGSMITH_API_KEY"] = getpass.getpass("Enter your LangSmith API key: ")# os.environ["LANGSMITH_TRACING"] = "true" Initialization? Basic Initialization? Below is a basic initialization, including the use of a directory to save the data locally. Select embeddings model:OpenAI?OpenAIAzureGoogle GeminiGoogle VertexAWSHuggingFaceOllamaCohereMistralAINomicNVIDIAVoyage AIIBM watsonxFakepip install -qU langchain-openaiimport getpassimport osif not os.environ.get("OPENAI_API_KEY"): os.environ["OPENAI_API_KEY"] = getpass.getpass("Enter API key for OpenAI: ")from langchain_openai import OpenAIEmbeddingsembeddings = OpenAIEmbeddings(model="text-embedding-3-large") Running Locally (In-Memory)? You can get a Chroma server running in memory by simply instantiating a Chroma instance with a collection name and your embeddings provider: from langchain_chroma import Chromavector_store = Chroma( collection_name="example_collection", embedding_function=embeddings,) If you don\'t need data persistence, this is a great option for experimenting while building your AI application with Langchain. Running Locally (with Data Persistence)? You can provide the persist_directory argument to save your data across multiple runs of your program: from langchain_chroma import Chromavector_store = Chroma( collection_name="example_collection", embedding_function=embeddings, persist_directory="./chroma_langchain_db",) Connecting to a Chroma Server? If you have a Chroma server running locally, or you have deployed one yourself, you can connect to it by providing the host argument. Fo...\n[Content truncated for length]\n\n=== Result 2: Chroma ===\nURL: https://python.langchain.com/docs/integrations/providers/chroma/\n\nChroma | ??? LangChain Skip to main contentOur Building Ambient Agents with LangGraph course is now available on LangChain Academy!On this page Chroma is a database for building AI applications with embeddings. Installation and Setup? pip install langchain-chroma VectorStore? There exists a wrapper around Chroma vector databases, allowing you to use it as a vectorstore, whether for semantic search or example selection. from langchain_chroma import Chroma For a more detailed walkthrough of the Chroma wrapper, see this notebook Retriever? See a usage example. from langchain.retrievers import SelfQueryRetrieverInstallation and SetupVectorStoreRetriever\n\n', annotations=None)] isError=False
Extracted Content: Documentation search results for 'Chroma DB integration' in langchain:

=== Result 1: Chroma ===
URL: https://python.langchain.com/docs/integrations/vectorstores/chroma/

Chroma | ??? LangChain Skip to main contentOur Building Ambient Agents with LangGraph course is now available on LangChain Academy!On this page This notebook covers how to get started with the Chroma vector store. Chroma is a AI-native open-source vector database focused on developer productivity and happiness. Chroma is licensed under Apache 2.0. View the full docs of Chroma at this page, and find the API reference for the LangChain integration at this page. Chroma CloudChroma Cloud powers serverless vector and full-text search. It's extremely fast, cost-effective, scalable and painless. Create a DB and try it out in under 30 seconds with $5 of free credits.Get started with Chroma Cloud Setup? To access Chroma vector stores you'll need to install the langchain-chroma integration package. pip install -qU "langchain-chroma>=0.1.2" Credentials? You can use the Chroma vector store without any credentials, simply installing the package above is enough! If you are a Chroma Cloud user, set your CHROMA_TENANT, CHROMA_DATABASE, and CHROMA_API_KEY environment variables. When you install the chromadb package you also get access to the Chroma CLI, which can set these for you. First, login via the CLI, and then use the connect command: chroma db connect [db_name] --env-file If you want to get best in-class automated tracing of your model calls you can also set your LangSmith API key by uncommenting below: # os.environ["LANGSMITH_API_KEY"] = getpass.getpass("Enter your LangSmith API key: ")# os.environ["LANGSMITH_TRACING"] = "true" Initialization? Basic Initialization? Below is a basic initialization, including the use of a directory to save the data locally. Select embeddings model:OpenAI?OpenAIAzureGoogle GeminiGoogle VertexAWSHuggingFaceOllamaCohereMistralAINomicNVIDIAVoyage AIIBM watsonxFakepip install -qU langchain-openaiimport getpassimport osif not os.environ.get("OPENAI_API_KEY"): os.environ["OPENAI_API_KEY"] = getpass.getpass("Enter API key for OpenAI: ")from langchain_openai import OpenAIEmbeddingsembeddings = OpenAIEmbeddings(model="text-embedding-3-large") Running Locally (In-Memory)? You can get a Chroma server running in memory by simply instantiating a Chroma instance with a collection name and your embeddings provider: from langchain_chroma import Chromavector_store = Chroma( collection_name="example_collection", embedding_function=embeddings,) If you don't need data persistence, this is a great option for experimenting while building your AI application with Langchain. Running Locally (with Data Persistence)? You can provide the persist_directory argument to save your data across multiple runs of your program: from langchain_chroma import Chromavector_store = Chroma( collection_name="example_collection", embedding_function=embeddings, persist_directory="./chroma_langchain_db",) Connecting to a Chroma Server? If you have a Chroma server running locally, or you have deployed one yourself, you can connect to it by providing the host argument. Fo...
[Content truncated for length]

=== Result 2: Chroma ===
URL: https://python.langchain.com/docs/integrations/providers/chroma/

Chroma | ??? LangChain Skip to main contentOur Building Ambient Agents with LangGraph course is now available on LangChain Academy!On this page Chroma is a database for building AI applications with embeddings. Installation and Setup? pip install langchain-chroma VectorStore? There exists a wrapper around Chroma vector databases, allowing you to use it as a vectorstore, whether for semantic search or example selection. from langchain_chroma import Chroma For a more detailed walkthrough of the Chroma wrapper, see this notebook Retriever? See a usage example. from langchain.retrievers import SelfQueryRetrieverInstallation and SetupVectorStoreRetriever